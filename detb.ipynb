{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c589d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ipdb;ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a4c21",
   "metadata": {},
   "source": [
    "NCCL_P2P_DISABLE=1, python -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 byol_main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206c77a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Using torch codce to gen masks\n",
    "import numpy as np\n",
    "import torch\n",
    "import skimage\n",
    "import pickle\n",
    "import torchvision\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \n",
    "    https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "def create_fh_mask(image, scale=1000, min_size=1000):\n",
    "    print(image.shape)\n",
    "    mask = felzenszwalb(image.permute(1,2,0), scale=scale, min_size=min_size)\n",
    "    return torch.tensor(mask).to(torch.int8)\n",
    "\n",
    "dataset_dir='/home/kkallidromitis/data/imagenet/train'\n",
    "\n",
    "totensor = torchvision.transforms.PILToTensor()\n",
    "image_dataset = ImageFolderWithPaths(dataset_dir,transform=totensor)\n",
    "#291 = n01440764/n01440764_13375.JPEG\n",
    "#724 = n01440764/n01440764_3849.JPEG\n",
    "image = image_dataset[724] \n",
    "plt.imshow(image[0].permute(1,2,0))\n",
    "plt.show()\n",
    "mask1 = create_fh_mask(image[0])\n",
    "plt.imshow(mask1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bc686",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(image[2])\n",
    "import pickle\n",
    "mask_path = '/home/kkallidromitis/data/imagenet/masks/train/n01440764_n01440764_3849_fh.pkl'\n",
    "with open(mask_path, 'rb') as f:\n",
    "    mask = pickle.load(f)\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f573a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_path = '/home/kkallidromitis/detconb/rand/image791.pkl'\n",
    "with open(img_path, 'rb') as f:\n",
    "    img = pickle.load(f)\n",
    "plt.imshow(img)\n",
    "#plt.show()\n",
    "mask_path = '/home/kkallidromitis/detconb/rand/mask791.pkl'\n",
    "with open(mask_path, 'rb') as f:\n",
    "    mask2 = pickle.load(f)\n",
    "plt.imshow(mask2.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd877311",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image[0][0,0,0],img[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import PIL \n",
    "PIL_image = Image.fromarray(np.uint8(img)).convert('RGB')\n",
    "\n",
    "PIL_image = PIL_image.save(\"./geek.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0].permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f01a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ce58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.io.read_image(\"./geek.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285471f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Checking if tf implementation gen same masks\n",
    "\n",
    "def _process_image(filename, coder, fh_scales, fh_min_sizes):\n",
    "  \"\"\"Process a single image file.\n",
    "\n",
    "  Args:\n",
    "    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "    fh_scales: Felzenzwalb-Huttenlocher segmentation scales.\n",
    "    fh_min_sizes: Felzenzwalb-Huttenlocher min segment sizes.\n",
    "  Returns:\n",
    "    image_buffer: string, JPEG encoding of RGB image.\n",
    "    height: integer, image height in pixels.\n",
    "    width: integer, image width in pixels.\n",
    "  \"\"\"\n",
    "  # Read the image file.\n",
    "  image_data = tf.gfile.GFile(filename, 'rb').read()\n",
    "\n",
    "  # Clean the dirty data.\n",
    "  if _is_png(filename):\n",
    "    # 1 image is a PNG.\n",
    "    print('Converting PNG to JPEG for %s' % filename)\n",
    "    image_data = coder.png_to_jpeg(image_data)\n",
    "  elif _is_cmyk(filename):\n",
    "    # 22 JPEG images are in CMYK colorspace.\n",
    "    print('Converting CMYK to RGB for %s' % filename)\n",
    "    image_data = coder.cmyk_to_rgb(image_data)\n",
    "\n",
    "  # Decode the RGB JPEG.\n",
    "  image = coder.decode_jpeg(image_data)\n",
    "\n",
    "  fh_segmentations = []\n",
    "  for i, fh_scale in enumerate(fh_scales):\n",
    "    fh = compute_fh_segmentation(image, fh_scale, fh_min_sizes[i])\n",
    "    fh_segmentations.append(fh)\n",
    "  fh_segmentations = np.stack(fh_segmentations)\n",
    "\n",
    "  # Check that image converted to RGB\n",
    "  assert len(image.shape) == 3\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "  assert image.shape[2] == 3\n",
    "\n",
    "  return image_data, fh_segmentations, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_binary_mask(mask,max_mask_id=256,pool_size=7):\n",
    "    batch_size = mask.shape[0]\n",
    "    mask_ids = torch.arange(max_mask_id).reshape(1,max_mask_id, 1, 1).float().to('cuda')\n",
    "    binary_mask = torch.eq(mask_ids, mask).float()\n",
    "    binary_mask = torch.nn.AdaptiveAvgPool2d((pool_size,pool_size))(binary_mask)\n",
    "    binary_mask = torch.reshape(binary_mask,(batch_size,max_mask_id,pool_size*pool_size)).permute(0,2,1)\n",
    "    binary_mask = torch.argmax(binary_mask, axis=-1)\n",
    "    binary_mask = torch.eye(max_mask_id)[binary_mask]\n",
    "    binary_mask = binary_mask.permute(0, 2, 1)\n",
    "    return binary_mask\n",
    "\n",
    "def create_binary_mask_tf(batch_size,num_pixels,masks,max_mask_id=256,downsample=(1, 32, 32, 1)):\n",
    "\n",
    "    fh_mask_to_use = self.config.model.fh_mask_to_use\n",
    "    mask = masks[..., fh_mask_to_use:(fh_mask_to_use+1)]\n",
    "\n",
    "    mask_ids = jnp.arange(max_mask_id).reshape(1, 1, 1, max_mask_id)\n",
    "    binary_mask = jnp.equal(mask_ids, mask).astype('float32')\n",
    "\n",
    "    binary_mask = hk.avg_pool(binary_mask, downsample, downsample, 'VALID')\n",
    "    binary_mask = binary_mask.reshape(batch_size, num_pixels, max_mask_id)\n",
    "    binary_mask = jnp.argmax(binary_mask, axis=-1)\n",
    "    binary_mask = jnp.eye(max_mask_id)[binary_mask]\n",
    "    binary_mask = jnp.transpose(binary_mask, [0, 2, 1])\n",
    "    return binary_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169402ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_masks(binary_mask,n_masks=16):\n",
    "    batch_size=binary_mask.shape[0]\n",
    "    mask_exists = torch.greater(binary_mask.sum(-1), 1e-3)\n",
    "    sel_masks = mask_exists.float() + 0.00000000001\n",
    "    sel_masks = sel_masks / sel_masks.sum(1, keepdims=True)\n",
    "    sel_masks = torch.log(sel_masks)\n",
    "    \n",
    "    dist = torch.distributions.categorical.Categorical(logits=sel_masks)\n",
    "    mask_ids = dist.sample([n_masks]).T\n",
    "    \n",
    "    sample_mask = torch.stack([binary_mask[b][mask_ids[b]] for b in range(batch_size)])\n",
    "    \n",
    "    return sample_mask,mask_ids\n",
    "\n",
    "def sample_masks(self, binary_mask, batch_size, n_random_vectors=16):\n",
    "    \"\"\"Samples which binary masks to use in the loss.\"\"\"\n",
    "    mask_exists = jnp.greater(binary_mask.sum(-1), 1e-3)\n",
    "    sel_masks = mask_exists.astype('float32') + 0.00000000001\n",
    "    sel_masks = sel_masks / sel_masks.sum(1, keepdims=True)\n",
    "    sel_masks = jnp.log(sel_masks)\n",
    "\n",
    "    mask_ids = jax.random.categorical(\n",
    "        hk.next_rng_key(), sel_masks, axis=-1,\n",
    "        shape=tuple([n_random_vectors, batch_size]))\n",
    "    mask_ids = jnp.transpose(mask_ids, [1, 0])\n",
    "\n",
    "    smpl_masks = jnp.stack(\n",
    "        [binary_mask[b][mask_ids[b]] for b in range(batch_size)])\n",
    "    return smpl_masks, mask_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29121d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "target1 = torch.load('./rand/target1.pt').cpu().detach()\n",
    "target2 = torch.load('./rand/target2.pt').cpu().detach()\n",
    "pred1 = torch.load('./rand/pred1.pt').cpu().detach()\n",
    "pred2 = torch.load('./rand/pred2.pt').cpu().detach()\n",
    "tind1 = torch.load('./rand/tind1.pt').cpu().detach()\n",
    "tind2 = torch.load('./rand/tind2.pt').cpu().detach()\n",
    "pind1 = torch.load('./rand/pind1.pt').cpu().detach()\n",
    "pind2 = torch.load('./rand/pind2.pt').cpu().detach()\n",
    "\n",
    "num_rois =16\n",
    "batch_size=128\n",
    "temperature=0.1\n",
    "max_val=1e9\n",
    "infinity_proxy =1e9\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def make_same_obj(ind_0, ind_1):\n",
    "    b = ind_0.shape[0]\n",
    "    same_obj = torch.eq(ind_0.reshape([b, num_rois, 1]),\n",
    "                         ind_1.reshape([b, 1, num_rois]))\n",
    "    return same_obj.float().unsqueeze(2)\n",
    "\n",
    "def manual_cross_entropy(labels, logits, weight):\n",
    "    ce = - weight * torch.sum(labels * torch.nn.functional.log_softmax(logits,dim = -1), dim=-1)\n",
    "    return torch.mean(ce)\n",
    "\n",
    "same_obj_aa = make_same_obj(pind1, tind1)\n",
    "same_obj_ab = make_same_obj(pind1, tind2)\n",
    "same_obj_ba = make_same_obj(pind2, tind1)\n",
    "same_obj_bb = make_same_obj(pind2, tind2)\n",
    "\n",
    "pred1 = torch.nn.functional.normalize(pred1,dim=-1)\n",
    "pred2 = torch.nn.functional.normalize(pred2,dim=-1)\n",
    "target1 = torch.nn.functional.normalize(target1,dim=-1)\n",
    "target2 = torch.nn.functional.normalize(target2,dim=-1)\n",
    "\n",
    "labels_local = torch.nn.functional.one_hot(torch.tensor(np.arange(batch_size))\n",
    "                                           ,batch_size).unsqueeze(1).unsqueeze(3)\n",
    "\n",
    "logits_aa = torch.einsum(\"abk,uvk->abuv\", pred1, target1) / temperature\n",
    "logits_bb = torch.einsum(\"abk,uvk->abuv\", pred2, target2) / temperature\n",
    "logits_ab = torch.einsum(\"abk,uvk->abuv\", pred1, target2) / temperature\n",
    "logits_ba = torch.einsum(\"abk,uvk->abuv\", pred2, target1) / temperature\n",
    "\n",
    "labels_aa = labels_local * same_obj_aa\n",
    "labels_ab = labels_local * same_obj_ab\n",
    "labels_ba = labels_local * same_obj_ba\n",
    "labels_bb = labels_local * same_obj_bb\n",
    "\n",
    "logits_aa = logits_aa - max_val * labels_local * same_obj_aa\n",
    "logits_bb = logits_bb - max_val * labels_local * same_obj_bb\n",
    "labels_aa = 0. * labels_aa\n",
    "labels_bb = 0. * labels_bb\n",
    "\n",
    "labels_abaa = torch.cat([labels_ab, labels_aa], axis=2)\n",
    "labels_babb = torch.cat([labels_ba, labels_bb], axis=2)\n",
    "\n",
    "labels_0 = torch.reshape(labels_abaa, [batch_size, num_rois, -1])\n",
    "labels_1 = torch.reshape(labels_babb, [batch_size, num_rois, -1])\n",
    "\n",
    "num_positives_0 = torch.sum(labels_0, axis=-1, keepdims=True)\n",
    "num_positives_1 = torch.sum(labels_1, axis=-1, keepdims=True)\n",
    "\n",
    "labels_0 = labels_0 / torch.max(num_positives_0, torch.ones(num_positives_0.shape))\n",
    "labels_1 = labels_1 / torch.max(num_positives_1, torch.ones(num_positives_1.shape))\n",
    "\n",
    "obj_area_0 = torch.sum(make_same_obj(pind1, pind1), axis=[2, 3])\n",
    "obj_area_1 = torch.sum(make_same_obj(pind2, pind2), axis=[2, 3])\n",
    "\n",
    "weights_0 = torch.greater(num_positives_0[..., 0], 1e-3).float()\n",
    "weights_0 = weights_0 / obj_area_0\n",
    "weights_1 = torch.greater(num_positives_1[..., 0], 1e-3).float()\n",
    "weights_1 = weights_1 / obj_area_1\n",
    "\n",
    "logits_abaa = torch.cat([logits_ab, logits_aa], axis=2)\n",
    "logits_babb = torch.cat([logits_ba, logits_bb], axis=2)\n",
    "\n",
    "logits_abaa = torch.reshape(logits_abaa, [batch_size, num_rois, -1])\n",
    "logits_babb = torch.reshape(logits_babb, [batch_size, num_rois, -1])\n",
    "\n",
    "loss_a = manual_cross_entropy(labels_0, logits_abaa, weights_0)\n",
    "loss_b = manual_cross_entropy(labels_1, logits_babb, weights_1)\n",
    "loss = loss_a + loss_b\n",
    "print(loss,loss_a,loss_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67399c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_abaa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837420ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.nn.functional.log_softmax(logits_abaa,dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae72f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target1 = torch.load('./rand/target1.pt').cpu().detach()\n",
    "target2 = torch.load('./rand/target2.pt').cpu().detach()\n",
    "pred1 = torch.load('./rand/pred1.pt').cpu().detach()\n",
    "pred2 = torch.load('./rand/pred2.pt').cpu().detach()\n",
    "tind1 = torch.load('./rand/tind1.pt').cpu().detach()\n",
    "tind2 = torch.load('./rand/tind2.pt').cpu().detach()\n",
    "pind1 = torch.load('./rand/pind1.pt').cpu().detach()\n",
    "pind2 = torch.load('./rand/pind2.pt').cpu().detach()\n",
    "target1 = target1.numpy()\n",
    "target2 = target2.numpy()\n",
    "pred1 = pred1.numpy()\n",
    "pred2 = pred2.numpy()\n",
    "tind1 = tind1.numpy()\n",
    "tind2 = tind2.numpy()\n",
    "pind1 = pind1.numpy()\n",
    "pind2 = pind2.numpy()\n",
    "\n",
    "def manual_cross_entropy(labels, logits, weight):\n",
    "  ce = - weight * np.sum(labels * tf.nn.log_softmax(logits), axis=-1)\n",
    "  return np.mean(ce)\n",
    "\n",
    "def make_same_obj(ind_0, ind_1):\n",
    "    same_obj = np.equal(ind_0.reshape([batch_size, num_rois, 1]),\n",
    "                     ind_1.reshape([batch_size, 1, num_rois]))\n",
    "    return np.expand_dims(same_obj.astype(\"float64\"), axis=2)\n",
    "\n",
    "same_obj_aa = make_same_obj(pind1, tind1)\n",
    "same_obj_ab = make_same_obj(pind1, tind2)\n",
    "same_obj_ba = make_same_obj(pind2, tind1)\n",
    "same_obj_bb = make_same_obj(pind2, tind2)\n",
    "\n",
    "# L2 normalize the tensors to use for the cosine-similarity\n",
    "pred1 = tf.math.l2_normalize(pred1, axis=-1)\n",
    "pred2 = tf.math.l2_normalize(pred2, axis=-1)\n",
    "target1 = tf.math.l2_normalize(target1, axis=-1)\n",
    "target2 = tf.math.l2_normalize(target2, axis=-1)\n",
    "\n",
    "target1_large = target1\n",
    "target2_large = target2\n",
    "\n",
    "labels_local = np.expand_dims(np.expand_dims(tf.one_hot(np.arange(batch_size),batch_size), axis=2), axis=1)\n",
    "\n",
    "# Do our matmuls and mask out appropriately.\n",
    "logits_aa = np.einsum(\"abk,uvk->abuv\", pred1, target1_large) / temperature\n",
    "logits_bb = np.einsum(\"abk,uvk->abuv\", pred2, target2_large) / temperature\n",
    "logits_ab = np.einsum(\"abk,uvk->abuv\", pred1, target2_large) / temperature\n",
    "logits_ba = np.einsum(\"abk,uvk->abuv\", pred2, target1_large) / temperature\n",
    "\n",
    "labels_aa = labels_local * same_obj_aa\n",
    "labels_ab = labels_local * same_obj_ab\n",
    "labels_ba = labels_local * same_obj_ba\n",
    "labels_bb = labels_local * same_obj_bb\n",
    "\n",
    "logits_aa = logits_aa - infinity_proxy * labels_local * same_obj_aa\n",
    "logits_bb = logits_bb - infinity_proxy * labels_local * same_obj_bb\n",
    "labels_aa = 0. * labels_aa\n",
    "labels_bb = 0. * labels_bb\n",
    "\n",
    "labels_abaa = np.concatenate([labels_ab, labels_aa], axis=2)\n",
    "labels_babb = np.concatenate([labels_ba, labels_bb], axis=2)\n",
    "\n",
    "labels_0 = np.reshape(labels_abaa, [batch_size, num_rois, -1])\n",
    "labels_1 = np.reshape(labels_babb, [batch_size, num_rois, -1])\n",
    "\n",
    "num_positives_0 = np.sum(labels_0, axis=-1, keepdims=True)\n",
    "num_positives_1 = np.sum(labels_1, axis=-1, keepdims=True)\n",
    "\n",
    "labels_0 = labels_0 / np.maximum(num_positives_0, 1)\n",
    "labels_1 = labels_1 / np.maximum(num_positives_1, 1)\n",
    "\n",
    "obj_area_0 = tf.math.reduce_sum(make_same_obj(pind1, pind1),axis=[2, 3])\n",
    "obj_area_1 = tf.math.reduce_sum(make_same_obj(pind2, pind2),axis=[2, 3])\n",
    "\n",
    "weights_0 = np.greater(num_positives_0[..., 0], 1e-3).astype(\"float64\")\n",
    "weights_0 = weights_0 / obj_area_0\n",
    "weights_1 = np.greater(num_positives_1[..., 0], 1e-3).astype(\"float64\")\n",
    "weights_1 = weights_1 / obj_area_1\n",
    "\n",
    "logits_abaa = np.concatenate([logits_ab, logits_aa], axis=2)\n",
    "logits_babb = np.concatenate([logits_ba, logits_bb], axis=2)\n",
    "\n",
    "logits_abaa = np.reshape(logits_abaa, [batch_size, num_rois, -1])\n",
    "logits_babb = np.reshape(logits_babb, [batch_size, num_rois, -1])\n",
    "\n",
    "loss_a = manual_cross_entropy(labels_0, logits_abaa, weights_0)\n",
    "loss_b = manual_cross_entropy(labels_1, logits_babb, weights_1)\n",
    "loss = loss_a + loss_b\n",
    "print(loss,loss_a,loss_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e04636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.nn.log_softmax(logits_abaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395a512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
