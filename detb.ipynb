{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c589d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ipdb;ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a4c21",
   "metadata": {},
   "source": [
    "python -m torch.distributed.launch --nproc_per_node=1 --nnodes=1 byol_main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957683e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984d58bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0559) tensor(1.5296) tensor(1.5263)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "target1 = torch.load('./rand/target1.pt').cpu().detach()\n",
    "target2 = torch.load('./rand/target2.pt').cpu().detach()\n",
    "pred1 = torch.load('./rand/pred1.pt').cpu().detach()\n",
    "pred2 = torch.load('./rand/pred2.pt').cpu().detach()\n",
    "tind1 = torch.load('./rand/tind1.pt').cpu().detach()\n",
    "tind2 = torch.load('./rand/tind2.pt').cpu().detach()\n",
    "pind1 = torch.load('./rand/pind1.pt').cpu().detach()\n",
    "pind2 = torch.load('./rand/pind2.pt').cpu().detach()\n",
    "\n",
    "num_rois =16\n",
    "batch_size=128\n",
    "temperature=0.1\n",
    "max_val=1e9\n",
    "infinity_proxy =1e9\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def make_same_obj(ind_0, ind_1):\n",
    "    b = ind_0.shape[0]\n",
    "    same_obj = torch.eq(ind_0.reshape([b, num_rois, 1]),\n",
    "                         ind_1.reshape([b, 1, num_rois]))\n",
    "    return same_obj.float().unsqueeze(2)\n",
    "\n",
    "def manual_cross_entropy(labels, logits, weight):\n",
    "    ce = - weight * torch.sum(labels * torch.nn.functional.log_softmax(logits,dim = -1), dim=-1)\n",
    "    return torch.mean(ce)\n",
    "\n",
    "same_obj_aa = make_same_obj(pind1, tind1)\n",
    "same_obj_ab = make_same_obj(pind1, tind2)\n",
    "same_obj_ba = make_same_obj(pind2, tind1)\n",
    "same_obj_bb = make_same_obj(pind2, tind2)\n",
    "\n",
    "pred1 = torch.nn.functional.normalize(pred1,dim=-1)\n",
    "pred2 = torch.nn.functional.normalize(pred2,dim=-1)\n",
    "target1 = torch.nn.functional.normalize(target1,dim=-1)\n",
    "target2 = torch.nn.functional.normalize(target2,dim=-1)\n",
    "\n",
    "labels_local = torch.nn.functional.one_hot(torch.tensor(np.arange(batch_size))\n",
    "                                           ,batch_size).unsqueeze(1).unsqueeze(3)\n",
    "\n",
    "logits_aa = torch.einsum(\"abk,uvk->abuv\", pred1, target1) / temperature\n",
    "logits_bb = torch.einsum(\"abk,uvk->abuv\", pred2, target2) / temperature\n",
    "logits_ab = torch.einsum(\"abk,uvk->abuv\", pred1, target2) / temperature\n",
    "logits_ba = torch.einsum(\"abk,uvk->abuv\", pred2, target1) / temperature\n",
    "\n",
    "labels_aa = labels_local * same_obj_aa\n",
    "labels_ab = labels_local * same_obj_ab\n",
    "labels_ba = labels_local * same_obj_ba\n",
    "labels_bb = labels_local * same_obj_bb\n",
    "\n",
    "logits_aa = logits_aa - max_val * labels_local * same_obj_aa\n",
    "logits_bb = logits_bb - max_val * labels_local * same_obj_bb\n",
    "labels_aa = 0. * labels_aa\n",
    "labels_bb = 0. * labels_bb\n",
    "\n",
    "labels_abaa = torch.cat([labels_ab, labels_aa], axis=2)\n",
    "labels_babb = torch.cat([labels_ba, labels_bb], axis=2)\n",
    "\n",
    "labels_0 = torch.reshape(labels_abaa, [batch_size, num_rois, -1])\n",
    "labels_1 = torch.reshape(labels_babb, [batch_size, num_rois, -1])\n",
    "\n",
    "num_positives_0 = torch.sum(labels_0, axis=-1, keepdims=True)\n",
    "num_positives_1 = torch.sum(labels_1, axis=-1, keepdims=True)\n",
    "\n",
    "labels_0 = labels_0 / torch.max(num_positives_0, torch.ones(num_positives_0.shape))\n",
    "labels_1 = labels_1 / torch.max(num_positives_1, torch.ones(num_positives_1.shape))\n",
    "\n",
    "obj_area_0 = torch.sum(make_same_obj(pind1, pind1), axis=[2, 3])\n",
    "obj_area_1 = torch.sum(make_same_obj(pind2, pind2), axis=[2, 3])\n",
    "\n",
    "weights_0 = torch.greater(num_positives_0[..., 0], 1e-3).float()\n",
    "weights_0 = weights_0 / obj_area_0\n",
    "weights_1 = torch.greater(num_positives_1[..., 0], 1e-3).float()\n",
    "weights_1 = weights_1 / obj_area_1\n",
    "\n",
    "logits_abaa = torch.cat([logits_ab, logits_aa], axis=2)\n",
    "logits_babb = torch.cat([logits_ba, logits_bb], axis=2)\n",
    "\n",
    "logits_abaa = torch.reshape(logits_abaa, [batch_size, num_rois, -1])\n",
    "logits_babb = torch.reshape(logits_babb, [batch_size, num_rois, -1])\n",
    "\n",
    "loss_a = manual_cross_entropy(labels_0, logits_abaa, weights_0)\n",
    "loss_b = manual_cross_entropy(labels_1, logits_babb, weights_1)\n",
    "loss = loss_a + loss_b\n",
    "print(loss,loss_a,loss_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67399c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 16, 4096])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_abaa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837420ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.4685e+00, -8.5617e+00, -8.2342e+00,  ..., -8.3697e+00,\n",
       "          -8.4482e+00, -8.3696e+00],\n",
       "         [-8.5290e+00, -8.4105e+00, -8.0042e+00,  ..., -8.3132e+00,\n",
       "          -8.4086e+00, -8.3132e+00],\n",
       "         [-8.4688e+00, -8.5615e+00, -8.2323e+00,  ..., -8.3689e+00,\n",
       "          -8.4491e+00, -8.3688e+00],\n",
       "         ...,\n",
       "         [-8.5515e+00, -8.4852e+00, -7.9304e+00,  ..., -8.3183e+00,\n",
       "          -8.3675e+00, -8.3181e+00],\n",
       "         [-8.4694e+00, -8.5612e+00, -8.2298e+00,  ..., -8.3681e+00,\n",
       "          -8.4499e+00, -8.3680e+00],\n",
       "         [-8.5523e+00, -8.4849e+00, -7.9280e+00,  ..., -8.3180e+00,\n",
       "          -8.3681e+00, -8.3178e+00]],\n",
       "\n",
       "        [[-8.4233e+00, -8.5514e+00, -8.4502e+00,  ..., -8.4930e+00,\n",
       "          -8.3708e+00, -8.4929e+00],\n",
       "         [-8.4451e+00, -8.6734e+00, -8.4437e+00,  ..., -8.4095e+00,\n",
       "          -8.3473e+00, -8.4095e+00],\n",
       "         [-8.4868e+00, -8.5398e+00, -8.3218e+00,  ..., -8.4683e+00,\n",
       "          -8.3699e+00, -8.4683e+00],\n",
       "         ...,\n",
       "         [-8.4452e+00, -8.6732e+00, -8.4435e+00,  ..., -8.4087e+00,\n",
       "          -8.3477e+00, -8.4087e+00],\n",
       "         [-8.4892e+00, -8.5399e+00, -8.3139e+00,  ..., -8.4679e+00,\n",
       "          -8.3708e+00, -8.4680e+00],\n",
       "         [-8.4894e+00, -8.5402e+00, -8.3141e+00,  ..., -8.4678e+00,\n",
       "          -8.3708e+00, -8.4678e+00]],\n",
       "\n",
       "        [[-8.4454e+00, -8.5511e+00, -8.3341e+00,  ..., -8.4128e+00,\n",
       "          -8.3296e+00, -8.4128e+00],\n",
       "         [-8.4466e+00, -8.5516e+00, -8.3283e+00,  ..., -8.4107e+00,\n",
       "          -8.3306e+00, -8.4106e+00],\n",
       "         [-8.4469e+00, -8.5516e+00, -8.3278e+00,  ..., -8.4103e+00,\n",
       "          -8.3308e+00, -8.4103e+00],\n",
       "         ...,\n",
       "         [-8.4467e+00, -8.5512e+00, -8.3282e+00,  ..., -8.4103e+00,\n",
       "          -8.3308e+00, -8.4102e+00],\n",
       "         [-8.4485e+00, -8.5517e+00, -8.3207e+00,  ..., -8.4079e+00,\n",
       "          -8.3319e+00, -8.4079e+00],\n",
       "         [-8.4483e+00, -8.5518e+00, -8.3207e+00,  ..., -8.4080e+00,\n",
       "          -8.3316e+00, -8.4079e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-8.5934e+00, -8.4760e+00, -8.3521e+00,  ..., -8.4294e+00,\n",
       "          -8.5583e+00, -8.4291e+00],\n",
       "         [-8.5938e+00, -8.4757e+00, -8.3510e+00,  ..., -8.4291e+00,\n",
       "          -8.5586e+00, -8.4289e+00],\n",
       "         [-8.3661e+00, -8.5516e+00, -8.1727e+00,  ..., -8.3222e+00,\n",
       "          -8.4148e+00, -8.3222e+00],\n",
       "         ...,\n",
       "         [-8.2928e+00, -8.1235e+00, -8.3367e+00,  ..., -8.5397e+00,\n",
       "          -8.2307e+00, -8.5394e+00],\n",
       "         [-8.3667e+00, -8.5513e+00, -8.1708e+00,  ..., -8.3213e+00,\n",
       "          -8.4154e+00, -8.3214e+00],\n",
       "         [-8.4581e+00, -8.4964e+00, -8.1171e+00,  ..., -8.4366e+00,\n",
       "          -8.3630e+00, -8.4365e+00]],\n",
       "\n",
       "        [[-8.4772e+00, -8.4866e+00, -8.1306e+00,  ..., -8.3884e+00,\n",
       "          -8.4046e+00, -8.3884e+00],\n",
       "         [-8.4266e+00, -8.2084e+00, -8.2931e+00,  ..., -8.4357e+00,\n",
       "          -8.4525e+00, -8.4356e+00],\n",
       "         [-8.4410e+00, -8.4635e+00, -8.2984e+00,  ..., -8.2620e+00,\n",
       "          -8.3444e+00, -8.2621e+00],\n",
       "         ...,\n",
       "         [-8.5049e+00, -8.6186e+00, -8.3459e+00,  ..., -8.4412e+00,\n",
       "          -8.4207e+00, -8.4412e+00],\n",
       "         [-8.4432e+00, -8.4622e+00, -8.2932e+00,  ..., -8.2611e+00,\n",
       "          -8.3456e+00, -8.2612e+00],\n",
       "         [-8.4791e+00, -8.4845e+00, -8.1181e+00,  ..., -8.3849e+00,\n",
       "          -8.4066e+00, -8.3849e+00]],\n",
       "\n",
       "        [[-8.4340e+00, -8.6366e+00, -8.4361e+00,  ..., -8.4143e+00,\n",
       "          -8.3552e+00, -8.4144e+00],\n",
       "         [-8.4366e+00, -8.6357e+00, -8.4290e+00,  ..., -8.4121e+00,\n",
       "          -8.3552e+00, -8.4122e+00],\n",
       "         [-8.2842e+00, -8.7129e+00, -8.2101e+00,  ..., -1.0000e+09,\n",
       "          -8.4698e+00, -1.0000e+09],\n",
       "         ...,\n",
       "         [-8.4495e+00, -8.4997e+00, -8.3888e+00,  ..., -8.4788e+00,\n",
       "          -1.0000e+09, -8.4788e+00],\n",
       "         [-8.4516e+00, -8.4989e+00, -8.3827e+00,  ..., -8.4789e+00,\n",
       "          -1.0000e+09, -8.4788e+00],\n",
       "         [-8.2858e+00, -8.7126e+00, -8.2051e+00,  ..., -1.0000e+09,\n",
       "          -8.4713e+00, -1.0000e+09]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.log_softmax(logits_abaa,dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dae72f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.055886189682516 1.5296317285339436 1.5262544611485722\n"
     ]
    }
   ],
   "source": [
    "target1 = torch.load('./rand/target1.pt').cpu().detach()\n",
    "target2 = torch.load('./rand/target2.pt').cpu().detach()\n",
    "pred1 = torch.load('./rand/pred1.pt').cpu().detach()\n",
    "pred2 = torch.load('./rand/pred2.pt').cpu().detach()\n",
    "tind1 = torch.load('./rand/tind1.pt').cpu().detach()\n",
    "tind2 = torch.load('./rand/tind2.pt').cpu().detach()\n",
    "pind1 = torch.load('./rand/pind1.pt').cpu().detach()\n",
    "pind2 = torch.load('./rand/pind2.pt').cpu().detach()\n",
    "target1 = target1.numpy()\n",
    "target2 = target2.numpy()\n",
    "pred1 = pred1.numpy()\n",
    "pred2 = pred2.numpy()\n",
    "tind1 = tind1.numpy()\n",
    "tind2 = tind2.numpy()\n",
    "pind1 = pind1.numpy()\n",
    "pind2 = pind2.numpy()\n",
    "\n",
    "def manual_cross_entropy(labels, logits, weight):\n",
    "  ce = - weight * np.sum(labels * tf.nn.log_softmax(logits), axis=-1)\n",
    "  return np.mean(ce)\n",
    "\n",
    "def make_same_obj(ind_0, ind_1):\n",
    "    same_obj = np.equal(ind_0.reshape([batch_size, num_rois, 1]),\n",
    "                     ind_1.reshape([batch_size, 1, num_rois]))\n",
    "    return np.expand_dims(same_obj.astype(\"float64\"), axis=2)\n",
    "\n",
    "same_obj_aa = make_same_obj(pind1, tind1)\n",
    "same_obj_ab = make_same_obj(pind1, tind2)\n",
    "same_obj_ba = make_same_obj(pind2, tind1)\n",
    "same_obj_bb = make_same_obj(pind2, tind2)\n",
    "\n",
    "# L2 normalize the tensors to use for the cosine-similarity\n",
    "pred1 = tf.math.l2_normalize(pred1, axis=-1)\n",
    "pred2 = tf.math.l2_normalize(pred2, axis=-1)\n",
    "target1 = tf.math.l2_normalize(target1, axis=-1)\n",
    "target2 = tf.math.l2_normalize(target2, axis=-1)\n",
    "\n",
    "target1_large = target1\n",
    "target2_large = target2\n",
    "\n",
    "labels_local = np.expand_dims(np.expand_dims(tf.one_hot(np.arange(batch_size),batch_size), axis=2), axis=1)\n",
    "\n",
    "# Do our matmuls and mask out appropriately.\n",
    "logits_aa = np.einsum(\"abk,uvk->abuv\", pred1, target1_large) / temperature\n",
    "logits_bb = np.einsum(\"abk,uvk->abuv\", pred2, target2_large) / temperature\n",
    "logits_ab = np.einsum(\"abk,uvk->abuv\", pred1, target2_large) / temperature\n",
    "logits_ba = np.einsum(\"abk,uvk->abuv\", pred2, target1_large) / temperature\n",
    "\n",
    "labels_aa = labels_local * same_obj_aa\n",
    "labels_ab = labels_local * same_obj_ab\n",
    "labels_ba = labels_local * same_obj_ba\n",
    "labels_bb = labels_local * same_obj_bb\n",
    "\n",
    "logits_aa = logits_aa - infinity_proxy * labels_local * same_obj_aa\n",
    "logits_bb = logits_bb - infinity_proxy * labels_local * same_obj_bb\n",
    "labels_aa = 0. * labels_aa\n",
    "labels_bb = 0. * labels_bb\n",
    "\n",
    "labels_abaa = np.concatenate([labels_ab, labels_aa], axis=2)\n",
    "labels_babb = np.concatenate([labels_ba, labels_bb], axis=2)\n",
    "\n",
    "labels_0 = np.reshape(labels_abaa, [batch_size, num_rois, -1])\n",
    "labels_1 = np.reshape(labels_babb, [batch_size, num_rois, -1])\n",
    "\n",
    "num_positives_0 = np.sum(labels_0, axis=-1, keepdims=True)\n",
    "num_positives_1 = np.sum(labels_1, axis=-1, keepdims=True)\n",
    "\n",
    "labels_0 = labels_0 / np.maximum(num_positives_0, 1)\n",
    "labels_1 = labels_1 / np.maximum(num_positives_1, 1)\n",
    "\n",
    "obj_area_0 = tf.math.reduce_sum(make_same_obj(pind1, pind1),axis=[2, 3])\n",
    "obj_area_1 = tf.math.reduce_sum(make_same_obj(pind2, pind2),axis=[2, 3])\n",
    "\n",
    "weights_0 = np.greater(num_positives_0[..., 0], 1e-3).astype(\"float64\")\n",
    "weights_0 = weights_0 / obj_area_0\n",
    "weights_1 = np.greater(num_positives_1[..., 0], 1e-3).astype(\"float64\")\n",
    "weights_1 = weights_1 / obj_area_1\n",
    "\n",
    "logits_abaa = np.concatenate([logits_ab, logits_aa], axis=2)\n",
    "logits_babb = np.concatenate([logits_ba, logits_bb], axis=2)\n",
    "\n",
    "logits_abaa = np.reshape(logits_abaa, [batch_size, num_rois, -1])\n",
    "logits_babb = np.reshape(logits_babb, [batch_size, num_rois, -1])\n",
    "\n",
    "loss_a = manual_cross_entropy(labels_0, logits_abaa, weights_0)\n",
    "loss_b = manual_cross_entropy(labels_1, logits_babb, weights_1)\n",
    "loss = loss_a + loss_b\n",
    "print(loss,loss_a,loss_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e04636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 16, 4096), dtype=float64, numpy=\n",
       "array([[[-8.46845501e+00, -8.56166970e+00, -8.23422962e+00, ...,\n",
       "         -8.36965763e+00, -8.44822865e+00, -8.36956691e+00],\n",
       "        [-8.52902360e+00, -8.41052498e+00, -8.00417946e+00, ...,\n",
       "         -8.31320967e+00, -8.40859892e+00, -8.31321277e+00],\n",
       "        [-8.46884644e+00, -8.56150585e+00, -8.23234910e+00, ...,\n",
       "         -8.36891967e+00, -8.44912416e+00, -8.36882788e+00],\n",
       "        ...,\n",
       "        [-8.55152328e+00, -8.48516716e+00, -7.93039675e+00, ...,\n",
       "         -8.31825586e+00, -8.36748172e+00, -8.31809582e+00],\n",
       "        [-8.46943384e+00, -8.56124329e+00, -8.22976886e+00, ...,\n",
       "         -8.36811071e+00, -8.44989287e+00, -8.36801892e+00],\n",
       "        [-8.55232382e+00, -8.48492581e+00, -7.92799716e+00, ...,\n",
       "         -8.31796521e+00, -8.36812813e+00, -8.31780577e+00]],\n",
       "\n",
       "       [[-8.42326112e+00, -8.55138315e+00, -8.45024629e+00, ...,\n",
       "         -8.49301083e+00, -8.37082769e+00, -8.49292202e+00],\n",
       "        [-8.44513550e+00, -8.67339447e+00, -8.44373479e+00, ...,\n",
       "         -8.40950218e+00, -8.34733605e+00, -8.40954682e+00],\n",
       "        [-8.48682098e+00, -8.53982084e+00, -8.32184749e+00, ...,\n",
       "         -8.46831285e+00, -8.36994760e+00, -8.46833693e+00],\n",
       "        ...,\n",
       "        [-8.44517013e+00, -8.67318424e+00, -8.44353279e+00, ...,\n",
       "         -8.40869578e+00, -8.34767388e+00, -8.40874066e+00],\n",
       "        [-8.48915550e+00, -8.53989991e+00, -8.31386652e+00, ...,\n",
       "         -8.46794101e+00, -8.37074998e+00, -8.46796605e+00],\n",
       "        [-8.48944811e+00, -8.54016630e+00, -8.31413387e+00, ...,\n",
       "         -8.46775763e+00, -8.37077735e+00, -8.46778278e+00]],\n",
       "\n",
       "       [[-8.44538259e+00, -8.55113679e+00, -8.33406364e+00, ...,\n",
       "         -8.41280341e+00, -8.32955741e+00, -8.41275209e+00],\n",
       "        [-8.44661488e+00, -8.55157329e+00, -8.32825376e+00, ...,\n",
       "         -8.41067221e+00, -8.33058103e+00, -8.41062017e+00],\n",
       "        [-8.44687140e+00, -8.55159706e+00, -8.32777751e+00, ...,\n",
       "         -8.41030598e+00, -8.33080483e+00, -8.41025371e+00],\n",
       "        ...,\n",
       "        [-8.44667891e+00, -8.55119732e+00, -8.32816020e+00, ...,\n",
       "         -8.41026905e+00, -8.33080348e+00, -8.41021720e+00],\n",
       "        [-8.44846620e+00, -8.55168880e+00, -8.32071794e+00, ...,\n",
       "         -8.40791668e+00, -8.33194543e+00, -8.40786411e+00],\n",
       "        [-8.44825840e+00, -8.55180448e+00, -8.32073152e+00, ...,\n",
       "         -8.40796917e+00, -8.33163911e+00, -8.40791672e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-8.59335383e+00, -8.47595467e+00, -8.35207041e+00, ...,\n",
       "         -8.42935594e+00, -8.55830963e+00, -8.42910482e+00],\n",
       "        [-8.59383717e+00, -8.47570733e+00, -8.35100314e+00, ...,\n",
       "         -8.42913863e+00, -8.55859259e+00, -8.42888728e+00],\n",
       "        [-8.36610935e+00, -8.55157067e+00, -8.17266384e+00, ...,\n",
       "         -8.32219851e+00, -8.41475428e+00, -8.32223549e+00],\n",
       "        ...,\n",
       "        [-8.29277990e+00, -8.12349216e+00, -8.33671794e+00, ...,\n",
       "         -8.53972486e+00, -8.23070553e+00, -8.53942141e+00],\n",
       "        [-8.36674765e+00, -8.55128688e+00, -8.17082976e+00, ...,\n",
       "         -8.32133244e+00, -8.41539425e+00, -8.32136934e+00],\n",
       "        [-8.45812381e+00, -8.49636114e+00, -8.11708624e+00, ...,\n",
       "         -8.43655837e+00, -8.36304081e+00, -8.43644930e+00]],\n",
       "\n",
       "       [[-8.47724011e+00, -8.48654964e+00, -8.13057190e+00, ...,\n",
       "         -8.38840588e+00, -8.40463742e+00, -8.38835772e+00],\n",
       "        [-8.42658980e+00, -8.20835264e+00, -8.29306902e+00, ...,\n",
       "         -8.43573536e+00, -8.45254602e+00, -8.43558802e+00],\n",
       "        [-8.44105037e+00, -8.46346374e+00, -8.29837551e+00, ...,\n",
       "         -8.26203706e+00, -8.34443473e+00, -8.26212412e+00],\n",
       "        ...,\n",
       "        [-8.50488219e+00, -8.61857340e+00, -8.34594384e+00, ...,\n",
       "         -8.44122145e+00, -8.42074761e+00, -8.44117180e+00],\n",
       "        [-8.44320500e+00, -8.46223462e+00, -8.29315471e+00, ...,\n",
       "         -8.26106520e+00, -8.34560276e+00, -8.26115311e+00],\n",
       "        [-8.47907939e+00, -8.48449286e+00, -8.11814963e+00, ...,\n",
       "         -8.38491668e+00, -8.40655973e+00, -8.38486638e+00]],\n",
       "\n",
       "       [[-8.43397191e+00, -8.63660445e+00, -8.43610713e+00, ...,\n",
       "         -8.41432365e+00, -8.35524085e+00, -8.41435441e+00],\n",
       "        [-8.43657222e+00, -8.63569161e+00, -8.42898122e+00, ...,\n",
       "         -8.41213337e+00, -8.35524544e+00, -8.41216639e+00],\n",
       "        [-8.28422101e+00, -8.71294003e+00, -8.21012924e+00, ...,\n",
       "         -1.00000001e+09, -8.46978310e+00, -1.00000001e+09],\n",
       "        ...,\n",
       "        [-8.44949108e+00, -8.49966174e+00, -8.38881177e+00, ...,\n",
       "         -8.47881192e+00, -1.00000001e+09, -8.47877580e+00],\n",
       "        [-8.45158909e+00, -8.49886195e+00, -8.38269852e+00, ...,\n",
       "         -8.47885619e+00, -1.00000001e+09, -8.47881893e+00],\n",
       "        [-8.28575455e+00, -8.71261433e+00, -8.20513137e+00, ...,\n",
       "         -1.00000001e+09, -8.47129933e+00, -1.00000001e+09]]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.log_softmax(logits_abaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395a512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
