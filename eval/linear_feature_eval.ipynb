{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import yaml\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jacklishufan/detconb/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_mae import mae_vit_base_patch16_dec512d8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.byol_transform import *\n",
    "import numpy as np\n",
    "from model import BYOLModel\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from skimage.segmentation import slic\n",
    "from torchvision.models._utils import IntermediateLayerGetter\n",
    "from sklearn.cluster import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm==0.3.2 in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (0.3.2)\n",
      "Requirement already satisfied: torch>=1.0 in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from timm==0.3.2) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from timm==0.3.2) (0.12.0)\n",
      "Requirement already satisfied: typing_extensions in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from torch>=1.0->timm==0.3.2) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from torchvision->timm==0.3.2) (1.21.2)\n",
      "Requirement already satisfied: requests in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from torchvision->timm==0.3.2) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from torchvision->timm==0.3.2) (9.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from requests->torchvision->timm==0.3.2) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from requests->torchvision->timm==0.3.2) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from requests->torchvision->timm==0.3.2) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jacklishufan/miniconda3/envs/detectron/lib/python3.9/site-packages (from requests->torchvision->timm==0.3.2) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:8'\n",
    "with open('/home/jacklishufan/detconb/config/train_imagenet_300_vit.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config['rank']=0\n",
    "model = mae_vit_base_patch16_dec512d8b(norm_pix_loss=True)\n",
    "weight =  '/shared/jacklishufan/vit/checkpoint-299.pth'\n",
    "state = torch.load(weight,map_location='cpu')\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.keys()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(state['model'],strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model#.online_network.encoder.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedAutoencoderViT(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (decoder_embed): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (decoder_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  (decoder_pred): Linear(in_features=512, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "latent, mask, ids_restore = model.forward_encoder(torch.rand(1,3,224,224),0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 197, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491d13b42f02426eb64d160eecb54f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tqdm.notebook.tqdm(total=100) as pbar:     \n",
    "     for i in range(10):\n",
    "         pbar.update(10)\n",
    "         pbar.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderWrapperVit(\n",
       "  (encoder): MaskedAutoencoderViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (decoder_embed): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Yao load_and_convert\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "class EncoderWrapperVit(torch.nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.encoder = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        x,_,_ = self.encoder.forward_encoder(x,0.0)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "    \n",
    "device = torch.device('cuda:1')\n",
    "model = EncoderWrapperVit(encoder).to(device)\n",
    "#model_path = '../ckpt/detconb/04_20_23-31/04_20_23-31_resnet50_300.pth.tar'\n",
    "#pth_file = torch.load(model_path, map_location=device)\n",
    "#checkpoint = torch.load(model_path, map_location=device)['model']#['online_backbone']\n",
    "#state_dict = {}\n",
    "# length = len(model.encoder.state_dict())\n",
    "# for name, param in zip(model.encoder.state_dict(), list(checkpoint.values())[:length]):\n",
    "#     state_dict[name] = param\n",
    "# model.encoder.load_state_dict(state_dict, strict=True)\n",
    "#model =  torch.nn.DataParallel(model, device_ids=[1, 2, 3,4,5,6,7,8])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_transforms = torchvision.transforms.Compose([\n",
    "                                                    transforms.Resize((224, 224)), #FIXME: They only did smallest side resize to 224\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                                                    \n",
    "                                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n03532672',\n",
       " 'n01914609',\n",
       " 'n04273569',\n",
       " 'n13052670',\n",
       " 'n03259280',\n",
       " 'n02879718',\n",
       " 'n02443114',\n",
       " 'n02051845',\n",
       " 'n03633091',\n",
       " 'n03095699',\n",
       " 'n01530575',\n",
       " 'n02799071',\n",
       " 'n03125729',\n",
       " 'n04612504',\n",
       " 'n04285008',\n",
       " 'n04149813',\n",
       " 'n04204347',\n",
       " 'n10148035',\n",
       " 'n02116738',\n",
       " 'n01534433',\n",
       " 'n01817953',\n",
       " 'ILSVRC2012_devkit_t12.tar.gz',\n",
       " 'n02795169',\n",
       " 'n02092002',\n",
       " 'n03216828',\n",
       " 'n04074963',\n",
       " 'n03929660',\n",
       " 'n03942813',\n",
       " 'n04515003',\n",
       " 'n13133613',\n",
       " 'n03485407',\n",
       " 'n03297495',\n",
       " 'n02988304',\n",
       " 'n03337140',\n",
       " 'n09399592',\n",
       " 'n03000684',\n",
       " 'n07717556',\n",
       " 'n02951358',\n",
       " 'n04208210',\n",
       " 'n02802426',\n",
       " 'n03255030',\n",
       " 'n03250847',\n",
       " 'n03840681',\n",
       " 'n02099601',\n",
       " 'n04336792',\n",
       " 'n04443257',\n",
       " 'n04270147',\n",
       " 'n02342885',\n",
       " 'n01776313',\n",
       " 'n02092339',\n",
       " 'n03642806',\n",
       " 'n02672831',\n",
       " 'n02268853',\n",
       " 'n02786058',\n",
       " 'n01729977',\n",
       " 'n02492660',\n",
       " 'n03691459',\n",
       " 'n02410509',\n",
       " 'n03788365',\n",
       " 'n02704792',\n",
       " 'n03871628',\n",
       " 'n03944341',\n",
       " 'n03599486',\n",
       " 'n01667778',\n",
       " 'n02088238',\n",
       " 'n02129604',\n",
       " 'n02112350',\n",
       " 'n02120505',\n",
       " 'n02099267',\n",
       " 'n07892512',\n",
       " 'n01632777',\n",
       " 'n01877812',\n",
       " 'n02091244',\n",
       " 'n01669191',\n",
       " 'n02106030',\n",
       " 'n03958227',\n",
       " 'n03857828',\n",
       " 'n04392985',\n",
       " 'n02825657',\n",
       " 'n01855672',\n",
       " 'n02236044',\n",
       " 'n04019541',\n",
       " 'n03899768',\n",
       " 'n04086273',\n",
       " 'n02107312',\n",
       " 'n03240683',\n",
       " 'n02086646',\n",
       " 'n02325366',\n",
       " 'n03089624',\n",
       " 'n03666591',\n",
       " 'n02423022',\n",
       " 'n04483307',\n",
       " 'n03770439',\n",
       " 'n02006656',\n",
       " 'n04461696',\n",
       " 'n04532106',\n",
       " 'n03134739',\n",
       " 'n04033995',\n",
       " 'n07716906',\n",
       " 'n04118538',\n",
       " 'n02892201',\n",
       " 'n02090622',\n",
       " 'n02011460',\n",
       " 'n02101388',\n",
       " 'n04532670',\n",
       " 'n09193705',\n",
       " 'n02963159',\n",
       " 'n02110185',\n",
       " 'n02108089',\n",
       " 'n04501370',\n",
       " 'n02317335',\n",
       " 'n02481823',\n",
       " 'n04005630',\n",
       " 'n02782093',\n",
       " 'n04584207',\n",
       " 'n04049303',\n",
       " 'n03345487',\n",
       " 'n04548280',\n",
       " 'n02110806',\n",
       " 'n04447861',\n",
       " 'n03424325',\n",
       " 'n04553703',\n",
       " 'n03218198',\n",
       " 'n03476991',\n",
       " 'n02037110',\n",
       " 'n01537544',\n",
       " 'n02667093',\n",
       " 'n03483316',\n",
       " 'n03992509',\n",
       " 'n04116512',\n",
       " 'n03930313',\n",
       " 'n09428293',\n",
       " 'n04346328',\n",
       " 'n04509417',\n",
       " 'n03709823',\n",
       " 'n02002556',\n",
       " 'n04442312',\n",
       " 'n03032252',\n",
       " 'n02791270',\n",
       " 'n04141076',\n",
       " 'n02111500',\n",
       " 'n04070727',\n",
       " 'n04525305',\n",
       " 'n02992211',\n",
       " 'n02097474',\n",
       " 'n04557648',\n",
       " 'n02415577',\n",
       " 'n03991062',\n",
       " 'n03895866',\n",
       " 'n03584254',\n",
       " 'n03623198',\n",
       " 'n02690373',\n",
       " 'n01498041',\n",
       " 'n02138441',\n",
       " 'n02454379',\n",
       " 'n02860847',\n",
       " 'n02488702',\n",
       " 'n01631663',\n",
       " 'n02107683',\n",
       " 'n02099712',\n",
       " 'n04033901',\n",
       " 'n03127747',\n",
       " 'n01630670',\n",
       " 'n02231487',\n",
       " 'n06596364',\n",
       " 'n02408429',\n",
       " 'n04152593',\n",
       " 'n02793495',\n",
       " 'n02088364',\n",
       " 'n01829413',\n",
       " 'n11939491',\n",
       " 'n07613480',\n",
       " 'n03461385',\n",
       " 'n04344873',\n",
       " 'n02099429',\n",
       " 'n02100735',\n",
       " 'n02127052',\n",
       " 'n02794156',\n",
       " 'n03742115',\n",
       " 'n02883205',\n",
       " 'n07718747',\n",
       " 'n02077923',\n",
       " 'n02699494',\n",
       " 'n02909870',\n",
       " 'n04357314',\n",
       " 'n03180011',\n",
       " 'n03347037',\n",
       " 'n02111129',\n",
       " 'n02815834',\n",
       " 'n03794056',\n",
       " 'n03602883',\n",
       " 'n02101006',\n",
       " 'n04355338',\n",
       " 'n04467665',\n",
       " 'n02132136',\n",
       " 'n02007558',\n",
       " 'n02457408',\n",
       " 'n02966687',\n",
       " 'n02951585',\n",
       " 'n02229544',\n",
       " 'n04560804',\n",
       " 'n02892767',\n",
       " 'n03930630',\n",
       " 'n03584829',\n",
       " 'n02018207',\n",
       " 'n04067472',\n",
       " 'n03492542',\n",
       " 'n04404412',\n",
       " 'n04141975',\n",
       " 'n01688243',\n",
       " 'n01632458',\n",
       " 'n02930766',\n",
       " 'n04229816',\n",
       " 'n01622779',\n",
       " 'n07873807',\n",
       " 'n03887697',\n",
       " 'n02123045',\n",
       " 'n02104365',\n",
       " 'n03733805',\n",
       " 'n03710193',\n",
       " 'n03950228',\n",
       " 'n03649909',\n",
       " 'untar_stuff.sh',\n",
       " 'n07753592',\n",
       " 'n03769881',\n",
       " 'n02113023',\n",
       " 'n03868242',\n",
       " 'n02100583',\n",
       " 'n02106166',\n",
       " 'n04482393',\n",
       " 'n02606052',\n",
       " 'n03325584',\n",
       " 'n02730930',\n",
       " 'n03814906',\n",
       " 'n02808440',\n",
       " 'n03868863',\n",
       " 'n02105641',\n",
       " 'n02281406',\n",
       " 'n02444819',\n",
       " 'n02104029',\n",
       " 'n02437616',\n",
       " 'n03527444',\n",
       " 'n03888605',\n",
       " 'n02112137',\n",
       " 'n03837869',\n",
       " 'n03866082',\n",
       " 'n01751748',\n",
       " 'n07760859',\n",
       " 'n01491361',\n",
       " 'n03494278',\n",
       " 'n02206856',\n",
       " 'n04376876',\n",
       " 'n01742172',\n",
       " 'n04264628',\n",
       " 'n03792782',\n",
       " 'n02808304',\n",
       " 'n03100240',\n",
       " 'n04136333',\n",
       " 'n04162706',\n",
       " 'n02807133',\n",
       " 'n01945685',\n",
       " 'n12144580',\n",
       " 'n01847000',\n",
       " 'n01514859',\n",
       " 'n02018795',\n",
       " 'n02834397',\n",
       " 'n03825788',\n",
       " 'n03272562',\n",
       " 'n03146219',\n",
       " 'n03995372',\n",
       " 'n02264363',\n",
       " 'n01629819',\n",
       " 'n02319095',\n",
       " 'n01943899',\n",
       " 'n02123394',\n",
       " 'n03384352',\n",
       " 'n04418357',\n",
       " 'n12998815',\n",
       " 'n04235860',\n",
       " 'n02493793',\n",
       " 'n11879895',\n",
       " 'n02088094',\n",
       " 'n01784675',\n",
       " 'n01729322',\n",
       " 'n02172182',\n",
       " 'n02910353',\n",
       " 'n07932039',\n",
       " 'n04523525',\n",
       " 'n03447447',\n",
       " 'n04141327',\n",
       " 'n04133789',\n",
       " 'n04356056',\n",
       " 'n02113978',\n",
       " 'n02727426',\n",
       " 'n03376595',\n",
       " 'n02089973',\n",
       " 'n01774384',\n",
       " 'n03481172',\n",
       " 'n04456115',\n",
       " 'n03207743',\n",
       " 'n03733281',\n",
       " 'n03710637',\n",
       " 'n02441942',\n",
       " 'n01871265',\n",
       " 'n04540053',\n",
       " 'n04367480',\n",
       " 'n07734744',\n",
       " 'n03743016',\n",
       " 'n02012849',\n",
       " 'n02804610',\n",
       " 'n04507155',\n",
       " 'n03272010',\n",
       " 'n04252077',\n",
       " 'n02510455',\n",
       " 'n01774750',\n",
       " 'n03063689',\n",
       " 'n03976467',\n",
       " 'n01968897',\n",
       " 'n02106382',\n",
       " 'n03485794',\n",
       " 'n03220513',\n",
       " 'n07693725',\n",
       " 'n02108000',\n",
       " 'n02093991',\n",
       " 'n02093428',\n",
       " 'n03998194',\n",
       " 'n07248320',\n",
       " 'n03124170',\n",
       " 'n03977966',\n",
       " 'n03017168',\n",
       " 'n02692877',\n",
       " 'n03291819',\n",
       " 'n04370456',\n",
       " 'n04347754',\n",
       " 'n01641577',\n",
       " 'n04371774',\n",
       " 'n01728572',\n",
       " 'n02948072',\n",
       " 'n02804414',\n",
       " 'n02396427',\n",
       " 'n02137549',\n",
       " 'n03697007',\n",
       " 'n09229709',\n",
       " 'n02280649',\n",
       " 'n02965783',\n",
       " 'n02107908',\n",
       " 'n02119022',\n",
       " 'n03729826',\n",
       " 'n04310018',\n",
       " 'n01855032',\n",
       " 'n04131690',\n",
       " 'n01955084',\n",
       " 'n03935335',\n",
       " 'n12267677',\n",
       " 'n02980441',\n",
       " 'n02871525',\n",
       " 'n03777754',\n",
       " 'n03983396',\n",
       " 'n02097298',\n",
       " 'n07695742',\n",
       " 'n07614500',\n",
       " 'n07584110',\n",
       " 'n03207941',\n",
       " 'n02093859',\n",
       " 'n04252225',\n",
       " 'n07742313',\n",
       " 'n04275548',\n",
       " 'n01978287',\n",
       " 'n04238763',\n",
       " 'n02484975',\n",
       " 'n03476684',\n",
       " 'n01806567',\n",
       " 'n01770393',\n",
       " 'n02769748',\n",
       " 'n02276258',\n",
       " 'n04090263',\n",
       " 'n03026506',\n",
       " 'n03787032',\n",
       " 'n03937543',\n",
       " 'n03595614',\n",
       " 'n04465501',\n",
       " 'n02089867',\n",
       " 'n13054560',\n",
       " 'n04328186',\n",
       " 'n03045698',\n",
       " 'n02102040',\n",
       " 'n04554684',\n",
       " 'n03000134',\n",
       " 'n07718472',\n",
       " 'n02895154',\n",
       " 'n04522168',\n",
       " 'n03197337',\n",
       " 'n02134084',\n",
       " 'n04023962',\n",
       " 'n02097130',\n",
       " 'n01689811',\n",
       " 'n03788195',\n",
       " 'n04009552',\n",
       " 'n03127925',\n",
       " 'n02398521',\n",
       " 'n04536866',\n",
       " 'n03777568',\n",
       " 'n02095570',\n",
       " 'n02823750',\n",
       " 'n02504458',\n",
       " 'n01843383',\n",
       " 'n07802026',\n",
       " 'n03063599',\n",
       " 'n04417672',\n",
       " 'n03796401',\n",
       " 'n02088466',\n",
       " 'n03467068',\n",
       " 'n03637318',\n",
       " 'n01818515',\n",
       " 'n04330267',\n",
       " 'n01798484',\n",
       " 'n04487394',\n",
       " 'n02326432',\n",
       " 'n02174001',\n",
       " 'n01768244',\n",
       " 'n02091635',\n",
       " 'n03690938',\n",
       " 'n03000247',\n",
       " 'n01980166',\n",
       " 'n02120079',\n",
       " 'n02097047',\n",
       " 'n04263257',\n",
       " 'n04326547',\n",
       " 'n02113799',\n",
       " 'n02165105',\n",
       " 'n02486410',\n",
       " 'n04597913',\n",
       " 'n02115641',\n",
       " 'n02536864',\n",
       " 'n02526121',\n",
       " 'n03908618',\n",
       " 'n01560419',\n",
       " 'n02027492',\n",
       " 'n02101556',\n",
       " 'n03662601',\n",
       " 'n02112018',\n",
       " 'n02086240',\n",
       " 'n07871810',\n",
       " 'n03938244',\n",
       " 'n03496892',\n",
       " 'n01756291',\n",
       " 'n04317175',\n",
       " 'n02279972',\n",
       " 'n01608432',\n",
       " 'n02655020',\n",
       " 'n02486261',\n",
       " 'n07753113',\n",
       " 'n01667114',\n",
       " 'n02177972',\n",
       " 'n02105162',\n",
       " 'n01582220',\n",
       " 'n02256656',\n",
       " 'n01981276',\n",
       " 'n04026417',\n",
       " 'n02091134',\n",
       " 'n02442845',\n",
       " 'n01614925',\n",
       " 'n02128385',\n",
       " 'n02487347',\n",
       " 'n04192698',\n",
       " 'n12057211',\n",
       " 'n04146614',\n",
       " 'n04153751',\n",
       " 'n02090721',\n",
       " 'n02134418',\n",
       " 'n01484850',\n",
       " 'n07875152',\n",
       " 'n07615774',\n",
       " 'n01819313',\n",
       " 'n07590611',\n",
       " 'n04458633',\n",
       " 'n02190166',\n",
       " 'n02033041',\n",
       " 'n03720891',\n",
       " 'n02395406',\n",
       " 'n09332890',\n",
       " 'n07711569',\n",
       " 'n04542943',\n",
       " 'n01748264',\n",
       " 'n01882714',\n",
       " 'n03110669',\n",
       " 'n02497673',\n",
       " 'n01824575',\n",
       " 'n02102480',\n",
       " 'n04265275',\n",
       " 'n01773549',\n",
       " 'n02165456',\n",
       " 'n02107574',\n",
       " 'n02129165',\n",
       " 'n04228054',\n",
       " 'n01443537',\n",
       " 'n03016953',\n",
       " 'n04562935',\n",
       " 'n09468604',\n",
       " 'n04579432',\n",
       " 'n07717410',\n",
       " 'n02950826',\n",
       " 'n02097658',\n",
       " 'n07565083',\n",
       " 'n02113186',\n",
       " 'n03290653',\n",
       " 'n01806143',\n",
       " 'n03761084',\n",
       " 'n01695060',\n",
       " 'n02102318',\n",
       " 'n03874599',\n",
       " 'n03179701',\n",
       " 'n07579787',\n",
       " 'n02483362',\n",
       " 'n02939185',\n",
       " 'n02676566',\n",
       " 'n03903868',\n",
       " 'n01697457',\n",
       " 'n02114548',\n",
       " 'n03388043',\n",
       " 'n04120489',\n",
       " 'n02091467',\n",
       " 'n12768682',\n",
       " 'n01944390',\n",
       " 'n02493509',\n",
       " 'n03680355',\n",
       " 'n02840245',\n",
       " 'n02445715',\n",
       " 'n04127249',\n",
       " 'n01616318',\n",
       " 'n01740131',\n",
       " 'n03042490',\n",
       " 'n03658185',\n",
       " 'n04380533',\n",
       " 'n03673027',\n",
       " 'n04040759',\n",
       " 'n02437312',\n",
       " 'n01677366',\n",
       " 'n07730033',\n",
       " 'n03717622',\n",
       " 'n03933933',\n",
       " 'n02108915',\n",
       " 'n02443484',\n",
       " 'n02133161',\n",
       " 'n04243546',\n",
       " 'n03891251',\n",
       " 'n02123597',\n",
       " 'n01580077',\n",
       " 'n04592741',\n",
       " 'n04428191',\n",
       " 'n03590841',\n",
       " 'n02927161',\n",
       " 'n02233338',\n",
       " 'n01532829',\n",
       " 'n03495258',\n",
       " 'n03776460',\n",
       " 'n02113624',\n",
       " 'n03706229',\n",
       " 'n04332243',\n",
       " 'n07583066',\n",
       " 'n03920288',\n",
       " 'n04065272',\n",
       " 'n03478589',\n",
       " 'n07836838',\n",
       " 'n02093256',\n",
       " 'n01592084',\n",
       " 'n02013706',\n",
       " 'n04041544',\n",
       " 'n02087046',\n",
       " 'n03970156',\n",
       " 'n04552348',\n",
       " 'n02607072',\n",
       " 'n01990800',\n",
       " 'n04350905',\n",
       " 'n01682714',\n",
       " 'n04099969',\n",
       " 'n02791124',\n",
       " 'n02169497',\n",
       " 'n03841143',\n",
       " 'n01753488',\n",
       " 'n03379051',\n",
       " 'n04254120',\n",
       " 'n02093647',\n",
       " 'n02105251',\n",
       " 'n03372029',\n",
       " 'TRN_IMG.mat',\n",
       " 'n04004767',\n",
       " 'n03954731',\n",
       " 'n02259212',\n",
       " 'n04550184',\n",
       " 'n03388183',\n",
       " 'n03208938',\n",
       " 'n07715103',\n",
       " 'n03843555',\n",
       " 'n03791053',\n",
       " 'n02168699',\n",
       " 'n04604644',\n",
       " 'n04254680',\n",
       " 'n04311004',\n",
       " 'n03041632',\n",
       " 'n02835271',\n",
       " 'n02105412',\n",
       " 'n02992529',\n",
       " 'n03047690',\n",
       " 'n04355933',\n",
       " 'n03344393',\n",
       " 'n09256479',\n",
       " 'n02114712',\n",
       " 'n02002724',\n",
       " 'n01930112',\n",
       " 'n03947888',\n",
       " 'n03891332',\n",
       " 'n04311174',\n",
       " 'n02870880',\n",
       " 'n03018349',\n",
       " 'n03692522',\n",
       " 'n02071294',\n",
       " 'n02124075',\n",
       " 'n02708093',\n",
       " 'n01693334',\n",
       " 'n04081281',\n",
       " 'n03393912',\n",
       " 'n06359193',\n",
       " 'n02356798',\n",
       " '.fuse_hidden000532e100000003',\n",
       " 'n02111277',\n",
       " 'n02095889',\n",
       " 'n02500267',\n",
       " 'n03924679',\n",
       " 'n02114367',\n",
       " 'n02328150',\n",
       " 'n02701002',\n",
       " 'n04239074',\n",
       " 'n02096585',\n",
       " 'n02086079',\n",
       " 'n02028035',\n",
       " 'n03854065',\n",
       " 'n02966193',\n",
       " 'n04429376',\n",
       " 'n01950731',\n",
       " 'n04525038',\n",
       " 'n03759954',\n",
       " 'n02417914',\n",
       " 'n04111531',\n",
       " 'n02412080',\n",
       " 'n02877765',\n",
       " 'n04590129',\n",
       " 'n02017213',\n",
       " 'n02096051',\n",
       " 'n03355925',\n",
       " 'n09246464',\n",
       " 'n04479046',\n",
       " 'n02094258',\n",
       " 'n02009229',\n",
       " 'n02066245',\n",
       " 'n02097209',\n",
       " 'n02117135',\n",
       " 'n01773157',\n",
       " 'n04200800',\n",
       " 'n04125021',\n",
       " 'n01978455',\n",
       " 'n02074367',\n",
       " 'n01986214',\n",
       " 'n03888257',\n",
       " 'n02085782',\n",
       " 'n02361337',\n",
       " 'n02102177',\n",
       " 'n01755581',\n",
       " 'n03838899',\n",
       " 'n04548362',\n",
       " 'n02108551',\n",
       " 'n03627232',\n",
       " 'n02489166',\n",
       " 'n02978881',\n",
       " 'n07860988',\n",
       " 'n03877472',\n",
       " 'n03786901',\n",
       " 'n03770679',\n",
       " 'n04258138',\n",
       " 'n02787622',\n",
       " 'n01924916',\n",
       " 'n02109047',\n",
       " 'n03482405',\n",
       " 'n04366367',\n",
       " 'n02089078',\n",
       " 'n03710721',\n",
       " '.fuse_hidden000410ce00000001',\n",
       " 'n02094114',\n",
       " 'n12985857',\n",
       " 'n02100236',\n",
       " 'n06785654',\n",
       " 'n04389033',\n",
       " 'n01985128',\n",
       " 'n02167151',\n",
       " 'n03394916',\n",
       " 'n03785016',\n",
       " 'n01644900',\n",
       " 'n02490219',\n",
       " 'n09472597',\n",
       " 'n01828970',\n",
       " 'n03876231',\n",
       " 'n02509815',\n",
       " 'n02364673',\n",
       " 'n03594945',\n",
       " 'n03782006',\n",
       " 'n04371430',\n",
       " 'n03764736',\n",
       " 'n03775071',\n",
       " 'n03961711',\n",
       " 'n03188531',\n",
       " 'n04409515',\n",
       " 'n07697313',\n",
       " 'n03535780',\n",
       " 'n04147183',\n",
       " 'n02102973',\n",
       " 'n01770081',\n",
       " 'n03201208',\n",
       " 'n04596742',\n",
       " 'n02837789',\n",
       " 'n03775546',\n",
       " 'n02480855',\n",
       " 'n02403003',\n",
       " 'n03670208',\n",
       " 'n01692333',\n",
       " 'n04277352',\n",
       " 'n01728920',\n",
       " 'n04209133',\n",
       " 'n02814533',\n",
       " 'n03544143',\n",
       " 'n01795545',\n",
       " 'n01820546',\n",
       " 'n02096437',\n",
       " 'n01873310',\n",
       " 'n02106550',\n",
       " 'n03804744',\n",
       " 'n03457902',\n",
       " 'n07714571',\n",
       " 'n04325704',\n",
       " 'n04254777',\n",
       " 'n02087394',\n",
       " 'n04579145',\n",
       " 'n02096177',\n",
       " 'n03271574',\n",
       " 'n04487081',\n",
       " 'n02974003',\n",
       " 'n01737021',\n",
       " 'n02865351',\n",
       " 'n02640242',\n",
       " 'n02916936',\n",
       " 'n03388549',\n",
       " 'n01797886',\n",
       " 'n02093754',\n",
       " 'n03014705',\n",
       " 'n03452741',\n",
       " 'n07930864',\n",
       " 'n02977058',\n",
       " 'n02114855',\n",
       " 'n04591713',\n",
       " 'n01883070',\n",
       " 'n02128925',\n",
       " 'n04485082',\n",
       " 'n07745940',\n",
       " 'n03445777',\n",
       " 'n01984695',\n",
       " 'n01983481',\n",
       " 'n02814860',\n",
       " 'n02105505',\n",
       " 'n01518878',\n",
       " 'n03223299',\n",
       " 'n02447366',\n",
       " 'n04037443',\n",
       " 'n01494475',\n",
       " 'n03314780',\n",
       " 'n02788148',\n",
       " 'n02113712',\n",
       " 'n03982430',\n",
       " 'n03400231',\n",
       " 'n03874293',\n",
       " 'n01860187',\n",
       " 'n03630383',\n",
       " 'n02009912',\n",
       " 'n02096294',\n",
       " 'n04435653',\n",
       " 'n02098286',\n",
       " 'n04462240',\n",
       " 'n03530642',\n",
       " 'n02843684',\n",
       " 'n04154565',\n",
       " 'n02098413',\n",
       " 'n02110958',\n",
       " 'n03124043',\n",
       " 'n01744401',\n",
       " 'n03187595',\n",
       " 'n02100877',\n",
       " 'n02841315',\n",
       " 'n03976657',\n",
       " 'n03425413',\n",
       " 'n03450230',\n",
       " 'n01917289',\n",
       " 'n02971356',\n",
       " 'n07831146',\n",
       " 'n04599235',\n",
       " 'n01704323',\n",
       " 'n09835506',\n",
       " 'n02981792',\n",
       " 'n02110341',\n",
       " 'n02219486',\n",
       " 'n03956157',\n",
       " 'n03417042',\n",
       " 'n04204238',\n",
       " 'n02095314',\n",
       " 'n03902125',\n",
       " 'n02268443',\n",
       " 'n10565667',\n",
       " 'n03873416',\n",
       " 'n03773504',\n",
       " 'n03724870',\n",
       " 'n03085013',\n",
       " 'n07753275',\n",
       " 'n03028079',\n",
       " 'n04606251',\n",
       " 'n02056570',\n",
       " 'n07747607',\n",
       " 'n02110063',\n",
       " 'n02098105',\n",
       " 'n04118776',\n",
       " 'n03196217',\n",
       " 'n03884397',\n",
       " 'n02492035',\n",
       " 'n03793489',\n",
       " 'n01601694',\n",
       " 'n02504013',\n",
       " 'n02641379',\n",
       " 'n02494079',\n",
       " 'n01685808',\n",
       " 'n02123159',\n",
       " 'n03594734',\n",
       " 'n03980874',\n",
       " 'n02115913',\n",
       " 'n02105056',\n",
       " 'n04505470',\n",
       " 'n02917067',\n",
       " 'n01698640',\n",
       " 'n04201297',\n",
       " 'n02363005',\n",
       " 'n02085620',\n",
       " 'n03908714',\n",
       " 'n03929855',\n",
       " 'n02099849',\n",
       " 'n15075141',\n",
       " 'n07768694',\n",
       " 'n03534580',\n",
       " 'n01796340',\n",
       " 'n04493381',\n",
       " 'n03617480',\n",
       " 'n03676483',\n",
       " 'n04296562',\n",
       " 'n01558993',\n",
       " 'n02823428',\n",
       " 'n02025239',\n",
       " 'n02422699',\n",
       " 'n02125311',\n",
       " 'n03498962',\n",
       " 'n03598930',\n",
       " 'n02085936',\n",
       " 'n03721384',\n",
       " 'n03781244',\n",
       " 'n02346627',\n",
       " 'n02086910',\n",
       " 'n03814639',\n",
       " 'n03109150',\n",
       " 'n13044778',\n",
       " 'n02999410',\n",
       " 'n02281787',\n",
       " 'n03404251',\n",
       " 'n02894605',\n",
       " 'n03249569',\n",
       " 'n02091032',\n",
       " 'n02111889',\n",
       " 'n02859443',\n",
       " 'n01644373',\n",
       " 'n02797295',\n",
       " 'n01531178',\n",
       " 'n03529860',\n",
       " 'n13040303',\n",
       " 'n02979186',\n",
       " 'n03160309',\n",
       " 'n04069434',\n",
       " 'n02277742',\n",
       " 'n07880968',\n",
       " 'n04179913',\n",
       " 'n01734418',\n",
       " 'n02109961',\n",
       " 'n02783161',\n",
       " 'n03763968',\n",
       " 'n03447721',\n",
       " 'n02128757',\n",
       " 'n02790996',\n",
       " 'n02749479',\n",
       " 'n04286575',\n",
       " 'n02389026',\n",
       " 'n09421951',\n",
       " 'n03133878',\n",
       " 'n01775062',\n",
       " 'n02119789',\n",
       " 'n02226429',\n",
       " 'n02687172',\n",
       " 'n03733131',\n",
       " 'n04423845',\n",
       " 'n02422106',\n",
       " 'n07697537',\n",
       " 'n01514668',\n",
       " 'n02488291',\n",
       " 'n01739381',\n",
       " 'n07714990',\n",
       " 'n04008634',\n",
       " 'n03444034',\n",
       " 'n01843065',\n",
       " 'n02869837',\n",
       " 'n02110627',\n",
       " 'n04613696',\n",
       " 'n06794110',\n",
       " 'n04335435',\n",
       " 'n04251144',\n",
       " 'n01807496',\n",
       " 'n07749582',\n",
       " 'n01687978',\n",
       " 'n02321529',\n",
       " 'n01833805',\n",
       " 'n04486054',\n",
       " 'n02483708',\n",
       " 'n02777292',\n",
       " 'n02108422',\n",
       " 'n03538406',\n",
       " 'n09288635',\n",
       " 'n02514041',\n",
       " 'n02669723',\n",
       " 'n07716358',\n",
       " 'n04372370',\n",
       " 'n01749939',\n",
       " 'n03832673',\n",
       " 'n02397096',\n",
       " 'n02088632',\n",
       " 'n02480495',\n",
       " 'n04517823',\n",
       " 'n02106662',\n",
       " 'n02090379',\n",
       " 'n03075370',\n",
       " 'n01910747',\n",
       " 'n04398044',\n",
       " 'n03459775',\n",
       " 'n02091831',\n",
       " 'n02130308',\n",
       " 'n02391049',\n",
       " 'n02776631',\n",
       " 'n04589890',\n",
       " 'n01665541',\n",
       " 'n04399382',\n",
       " 'n02109525',\n",
       " 'n03126707',\n",
       " 'n02643566',\n",
       " 'n03916031',\n",
       " 'n03062245',\n",
       " 'n01735189',\n",
       " 'n01773797',\n",
       " 'n07684084',\n",
       " 'n03661043',\n",
       " 'n02112706',\n",
       " 'n04266014',\n",
       " 'n06874185',\n",
       " 'n02058221',\n",
       " 'n02666196',\n",
       " 'n01496331',\n",
       " 'n02747177',\n",
       " 'n04039381',\n",
       " 'n02107142',\n",
       " 'n04591157',\n",
       " 'n02094433',\n",
       " 'n03803284',\n",
       " 'n12620546',\n",
       " 'n03792972',\n",
       " 'n03141823',\n",
       " 'n07920052',\n",
       " 'n04209239',\n",
       " 'n03445924',\n",
       " 'n01694178',\n",
       " 'n07720875',\n",
       " 'n04259630',\n",
       " 'n13037406',\n",
       " 'n03131574',\n",
       " 'n03967562',\n",
       " 'n02906734',\n",
       " 'n03877845',\n",
       " 'n04476259',\n",
       " 'n01440764',\n",
       " 'n07754684',\n",
       " 'n03657121',\n",
       " 'n03065424',\n",
       " 'n02817516',\n",
       " 'n01675722',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('imagenet/images/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder('imagenet/images/train/', transform=data_transforms)\n",
    "\n",
    "test_dataset = datasets.ImageFolder('imagenet/images/val/', transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 224, 224])\n",
      "Input shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape:\", train_dataset.__getitem__(0)[0].shape)\n",
    "print(\"Input shape:\", test_dataset.__getitem__(0)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          num_workers=8, drop_last=False, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                          num_workers=8, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# encoder = ResNet18(**config['network'])\n",
    "encoder = model\n",
    "output_feature_dim = 2048 #encoder.projetion.net[0].in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(output_feature_dim, 1000)\n",
    "logreg = logreg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_from_encoder(encoder, loader):\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # get the features from the pre-trained model\n",
    "    for (x, y) in tqdm.notebook.tqdm((loader)):\n",
    "        with torch.no_grad():\n",
    "            feature_vector = encoder(x.to(device))\n",
    "            x_train.extend(feature_vector.cpu())\n",
    "            y_train.extend(y.cpu().numpy())\n",
    "\n",
    "    x_train = torch.stack(x_train)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Train Features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29441fbf5b6430888000a0d30452884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m encoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting Train Features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mget_features_from_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mget_features_from_encoder\u001b[0;34m(encoder, loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      9\u001b[0m         feature_vector \u001b[38;5;241m=\u001b[39m encoder(x\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m---> 10\u001b[0m         x_train\u001b[38;5;241m.\u001b[39mextend(\u001b[43mfeature_vector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m         y_train\u001b[38;5;241m.\u001b[39mextend(y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     13\u001b[0m x_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(x_train)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "print(\"Getting Train Features\")\n",
    "x_train, y_train = get_features_from_encoder(encoder, train_loader)\n",
    "# print(\"Getting Test Features\")\n",
    "# x_test, y_test = get_features_from_encoder(encoder, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          ...,\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
       " \n",
       "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          ...,\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
       " \n",
       "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          ...,\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting Test Features\")\n",
    "x_test, y_test = get_features_from_encoder(encoder, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(x_train.shape) > 2:\n",
    "    x_train = torch.mean(x_train, dim=[2, 3])\n",
    "    x_test = torch.mean(x_test, dim=[2, 3])\n",
    "    \n",
    "print(\"Training data shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(x_train.shape) > 2:\n",
    "    x_train = torch.mean(x_train, dim=[2, 3])\n",
    "    x_test = torch.mean(x_test, dim=[2, 3])\n",
    "    \n",
    "print(\"Training data shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True)\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=512, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They didn't do this!!!\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# scaler.fit(x_train)\n",
    "# x_train = scaler.transform(x_train).astype(np.float32)\n",
    "# x_test = scaler.transform(x_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loaders_from_arrays(x_train, y_train, x_test, y_test)\n",
    "#train_loader, test_loader = create_data_loaders_from_arrays(torch.from_numpy(x_train), y_train, torch.from_numpy(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(logreg.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "eval_every_n_epochs = 10\n",
    "\n",
    "for epoch in tqdm.notebook.tqdm((range(100))):\n",
    "#     train_acc = []\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()        \n",
    "        \n",
    "        logits = logreg(x)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    total = 0\n",
    "    if epoch % eval_every_n_epochs == 0:\n",
    "        correct = 0\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = logreg(x)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            total += y.size(0)\n",
    "            correct += (predictions == y).sum().item()\n",
    "            \n",
    "        acc = 100 * correct / total\n",
    "        print(f\"Testing accuracy: {np.mean(acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "\n",
    "correct = 0\n",
    "for x, y in test_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logits = logreg(x)\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "    total += y.size(0)\n",
    "    correct += (predictions == y).sum().item()\n",
    "\n",
    "acc = 100 * correct / total\n",
    "print(f\"Testing accuracy: {np.mean(acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "804af93a7b07038b76e2a0dedec33fad975659e88bbe386b90b44cf869a2866c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
